{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import collections\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'file:///Users/juliehembeck/Documents/Julie_Public_Polling/PetitionDataJulieCopy.csv'\n",
    "\n",
    "Petition = pd.read_csv(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "petition_background_list_animals = list(Petition.loc[Petition['petition_category'] == 'Animals', 'petition_background'])\n",
    "\n",
    "petition_background_list_crime = list(Petition.loc[Petition['petition_category'] == 'Crime/Safety', 'petition_background'])\n",
    "\n",
    "petition_background_list_education = list(Petition.loc[Petition['petition_category'] == 'Education', 'petition_background'])\n",
    "\n",
    "petition_background_list_entertainment = list(Petition.loc[Petition['petition_category'] == 'Entertainment/Spectation', 'petition_background'])\n",
    "\n",
    "petition_background_list_government = list(Petition.loc[Petition['petition_category'] == 'Government', 'petition_background'])\n",
    "\n",
    "petition_background_list_health = list(Petition.loc[Petition['petition_category'] == 'Health', 'petition_background'])\n",
    "\n",
    "\n",
    "petition_background_list_enviroment = list(Petition.loc[Petition['petition_category'] == 'Environment', 'petition_background'])\n",
    "\n",
    "\n",
    "petition_background_list_socialising = list(Petition.loc[Petition['petition_category'] == 'Socialising/Participation', 'petition_background'])\n",
    "\n",
    "\n",
    "petition_background_list_vehicles = list(Petition.loc[Petition['petition_category'] == 'Vehicles', 'petition_background'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_list = petition_background_list_vehicles\n",
    "#change based on what list we are analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "listToStr = '  '.join([str(elem) for elem in current_list]) \n",
    "\n",
    "current_list_string = listToStr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_list_sent = sent_tokenize(current_list_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Put pressure on world leaders including the United Nations and UNICEF to investigate the mass incarceration of Uighur Muslims and urge sanctions on China.',\n",
       " 'Additional Details: Under human and amnesty rights laws their rights to be Muslims and practice freely are being violated.',\n",
       " 'I want this highlighted immediately so Uighurs can return home.',\n",
       " 'UK government stands against all forms of oppression.',\n",
       " 'It fights for the freedom and rights of every citizen.',\n",
       " 'It allows Muslims to practice freely.',\n",
       " 'Islam stands for peace and UK recognises the strong bond UK Muslims have with diverse communities here.',\n",
       " 'We are grateful for this.',\n",
       " 'UK stood up for the black lives matter campaign with great success, now I believe UK government can truly put an end to the blatant indoctrination of Uyghur Muslims because in the past they have united against oppression.',\n",
       " 'Allow learner drivers to be passed if their driving instructors feels they are safe to drive due to the failure of the Government to enable learners to book a test.',\n",
       " 'Additional Details: It is unfair on learners who have been unable to book a test due to the pandemic to have to wait a significantly long time to be have access to booking one.',\n",
       " 'To tackle the ever-growing backlog of candidates waiting to take driving tests, it is vital that the DVSA immediately open all test centres to full capacity and post examiners back to the test centres that need them.',\n",
       " 'Social distancing between examiners can be achieved by staggering the test times.',\n",
       " 'Additional Details: The growing backlog is mostly due to the DVSA reducing the capacity of many local test centres and posting examiners to other centres many miles from where candidates live and learned to drive.',\n",
       " 'The booking system crashed on 21st Aug, and there was a queue of over 100,000 people when it reopened on 26th Aug.',\n",
       " 'It is also putting strain on the customer service call centres who are dealing with daily queues of up to 3 hours long.',\n",
       " 'Many people need their driving independence for work and some candidates have had their test on hold since March.']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_list_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(current_list_sent)):\n",
    "    current_list_sent[i] = current_list_sent[i].replace('\\n',' ')\n",
    "    current_list_sent[i] = current_list_sent[i].replace(\"'\", \"\")\n",
    "    current_list_sent[i] = current_list_sent[i].replace('\"', \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].replace(',', \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].replace('.', \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].replace('\"', \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].replace('’', \"\")  \n",
    "    current_list_sent[i] = current_list_sent[i].replace(':', \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].replace('-', \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].replace('(', \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].replace(')', \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].replace('&', \"and\")\n",
    "    current_list_sent[i] = current_list_sent[i].replace(';', \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].replace('?', \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].replace('%', \" percent\")\n",
    "    current_list_sent[i] = current_list_sent[i].replace(\"/\", \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].replace(\"–\", \" \")\n",
    "    current_list_sent[i] = current_list_sent[i].lower()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#Turn list into Text form for NLTK\n",
    "#Remove stop-words, will do this later\n",
    "\n",
    "#with open(\"current_list_sent.txt\", \"w\") as output:\n",
    "#    for row in petition_background_list_animals:\n",
    " #       output.write(str(row))\n",
    "        \n",
    "#raw = open('current_list_sent.txt').read()\n",
    "#raw_words_current = word_tokenize(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_current = []\n",
    "for i in range(len(current_list_sent)):\n",
    "       \n",
    "        for token in ngrams(current_list_sent[i].split(), 2):\n",
    "            phrases_current.append(' '.join(token))\n",
    "    \n",
    "        for token in ngrams(current_list_sent[i].split(), 3):\n",
    "            phrases_current.append(' '.join(token))\n",
    "    \n",
    "        for token in ngrams(current_list_sent[i].split(), 4):\n",
    "            phrases_current.append(' '.join(token))\n",
    "            \n",
    "        for token in ngrams(current_list_sent[i].split(), 5):\n",
    "            phrases_current.append(' '.join(token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'to the': 5, 'additional details': 3, 'to be': 3, 'due to': 3, 'due to the': 3, 'it is': 3, 'test centres': 3, 'muslims and': 2, 'practice freely': 2, 'uk government': 2, ...})"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_phrases = FreqDist(phrases_current)\n",
    "fdist_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = pd.DataFrame(list(fdist_phrases.items()), columns = [\"Phrase\",\"Frequency\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = current_data.sort_values(by=['Frequency'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = current_data.set_index('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>due to the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>additional details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test centres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can truly put an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>government can truly put</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uk government can truly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>believe uk government can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test on hold since march</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1203 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Phrase\n",
       "Frequency                           \n",
       "5                             to the\n",
       "3                         due to the\n",
       "3                 additional details\n",
       "3                       test centres\n",
       "3                              to be\n",
       "...                              ...\n",
       "1                   can truly put an\n",
       "1           government can truly put\n",
       "1            uk government can truly\n",
       "1          believe uk government can\n",
       "1           test on hold since march\n",
       "\n",
       "[1203 rows x 1 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data.to_csv('vehicles_phrases.csv') #change csv name based on list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
